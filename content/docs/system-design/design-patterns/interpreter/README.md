+++
title= "Interpreter Pattern"
tags = [ "system-design",  "design-patterns", "interpreter" ]
author = "Me"
showToc = true
TocOpen = false
draft = false
hidemeta = false
comments = true
disableShare = false
disableHLJS = false
hideSummary = false
searchHidden = true
ShowReadingTime = true
ShowBreadCrumbs = true
ShowPostNavLinks = true
ShowWordCount = true
ShowRssButtonInSectionTermList = true
UseHugoToc = true
+++

The **Interpreter Design Pattern** is a behavioral design pattern that defines a representation for the grammar of a language and an interpreter to parse and interpret sentences in the language. The pattern is widely used in compilers, interpreters, IDEs, and static code analysis tools to transform textual input into object-oriented structures.

The primary goal of the interpreter is to convert a sequence of tokens (derived from text) into an object structure that can be evaluated or processed.

### Key Components

The implementation of an interpreter involves two key components:

- **Lexing**: This process involves breaking the input text into a sequence of **tokens**.
- **Parsing**: The tokens are then parsed into an **expression tree**, which can be evaluated or transformed.

### Code Walkthrough

#### Token Representation

Tokens represent the smallest elements of the expression (such as numbers, operators, and parentheses). The `Token` class defines these elements.

```python
from enum import Enum, auto

class Token:
    class Type(Enum):
        INTEGER = auto()
        PLUS = auto()
        MINUS = auto()
        LEFT_PAREN = auto()
        RIGHT_PAREN = auto()

    def __init__(self, token_type, text):
        self.type = token_type
        self.text = text

    def __str__(self):
        return f"`{self.text}`"
```

- **Token Types**: We use an enum to define token types (e.g., INTEGER, PLUS, MINUS).
- **Token Class**: Each token has a type and a corresponding text value.

#### Lexing

The lexing process converts a string expression into a sequence of tokens. Each character is inspected, and tokens are created accordingly.

```python
def lex(input):
    result = []
    i = 0
    while i < len(input):
        if input[i] == '+':
            result.append(Token(Token.Type.PLUS, '+'))
        elif input[i] == '-':
            result.append(Token(Token.Type.MINUS, '-'))
        elif input[i] == '(':
            result.append(Token(Token.Type.LEFT_PAREN, '('))
        elif input[i] == ')':
            result.append(Token(Token.Type.RIGHT_PAREN, ')'))
        elif input[i].isdigit():
            digits = [input[i]]
            for j in range(i + 1, len(input)):
                if input[j].isdigit():
                    digits.append(input[j])
                    i += 1
                else:
                    break
            result.append(Token(Token.Type.INTEGER, ''.join(digits)))
        i += 1
    return result
```

- **Lexing Loop**: The loop inspects each character, determines its type, and adds it as a token to the result list.
- **Handling Integers**: Multiple digits are concatenated to form integer tokens.

#### Parsing

Parsing converts the tokens into an expression tree structure that can be evaluated later. This tree represents the order of operations in the expression.

```python
class Integer:
    def __init__(self, value):
        self.value = value

class BinaryExpression:
    class Type(Enum):
        ADDITION = auto()
        SUBTRACTION = auto()

    def __init__(self):
        self.type = None
        self.left = None
        self.right = None

def parse(tokens):
    result = BinaryExpression()
    have_lhs = False
    i = 0

    while i < len(tokens):
        token = tokens[i]

        if token.type == Token.Type.INTEGER:
            integer_value = Integer(int(token.text))
            if not have_lhs:
                result.left = integer_value
                have_lhs = True
            else:
                result.right = integer_value

        elif token.type == Token.Type.PLUS:
            result.type = BinaryExpression.Type.ADDITION

        elif token.type == Token.Type.MINUS:
            result.type = BinaryExpression.Type.SUBTRACTION

        elif token.type == Token.Type.LEFT_PAREN:
            j = i
            while j < len(tokens):
                if tokens[j].type == Token.Type.RIGHT_PAREN:
                    break
                j += 1
            subexpression = parse(tokens[i + 1:j])
            if not have_lhs:
                result.left = subexpression
                have_lhs = True
            else:
                result.right = subexpression
            i = j
        i += 1

    return result
```

- **BinaryExpression**: A binary expression is defined with a left-hand side (LHS), right-hand side (RHS), and an operation (e.g., addition, subtraction).
- **Parse Function**: It processes the tokens to build a binary tree representation of the expression. Subexpressions within parentheses are handled recursively.

#### Evaluation of Expression Tree

Once the expression is parsed into a tree, we can evaluate it by traversing the tree structure.

```python
class Integer:
    def __init__(self, value):
        self.value = value

    @property
    def value(self):
        return self.value

class BinaryExpression:
    class Type(Enum):
        ADDITION = auto()
        SUBTRACTION = auto()

    def __init__(self):
        self.type = None
        self.left = None
        self.right = None

    @property
    def value(self):
        if self.type == BinaryExpression.Type.ADDITION:
            return self.left.value + self.right.value
        elif self.type == BinaryExpression.Type.SUBTRACTION:
            return self.left.value - self.right.value
```

**Evaluation**: The value property recursively evaluates the binary expression tree. For ADDITION, the values of the left and right expressions are summed, while for SUBTRACTION, they are subtracted.

### Example Usage

Hereâ€™s a simple usage example where we lex, parse, and evaluate an arithmetic expression.

```python
expression = "(13 + 4) - (12 + 1)"
tokens = lex(expression)
parsed = parse(tokens)
result = parsed.value
print(f"Result: {result}")  # Output: Result: 4
```

- **Lexing**: The input expression `(13 + 4) - (12 + 1)` is converted into tokens.
- **Parsing**: Tokens are parsed into a binary expression tree.
- **Evaluation**: The expression tree is evaluated to give the result.

The interpreter design pattern is effective for building simple interpreters, parsers, and evaluators. It consists of two main processes: Lexing, which transforms input text into tokens, and Parsing, which converts tokens into an expression tree for evaluation. The structure allows easy extensions for additional operations or token types, making it adaptable for different types of textual data processing.
